This script can train a Stable Diffusion model to reconstruct the visual stimulus images received by mice through neural recording. The model is saved in the allen directory, where ddpm_ckpt_neuron_cond.pth is a Stable Diffusion model that reconstructs the image. The generated condition is a 25Ã—1 neural vector, which is the result of dimensionality reduction using CEBRA. vqvae_autoencoder_ckpt.pth is a VQ-VAE model that compresses the original image into latent space.

When using this script, you first want to use tools/train_vqvae.py to train a VQ-VAE model. Then you should use tools/train_ddpm_cond.py to train a stable diffusion model based on conditional generation. Finally, you can run sample_ddpm_text_cond.py to generate the image. Note that you need to specify the generated condition in this file.
